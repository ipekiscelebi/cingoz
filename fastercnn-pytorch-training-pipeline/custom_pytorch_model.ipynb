{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLXEx7TTiOQ_"
      },
      "source": [
        "## Configure dataset file paths and classes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run both code blocks below to change the dataset path and classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wc1raikijI5b",
        "outputId": "c5d0c8c8-98d4-4cf3-c514-a3ff26b9b42a"
      },
      "outputs": [],
      "source": [
        "%%writefile custom_data.yaml\n",
        "# Images and labels direcotry should be relative to train.py\n",
        "TRAIN_DIR_IMAGES: '../dataset/train'\n",
        "TRAIN_DIR_LABELS: '../dataset/train'\n",
        "VALID_DIR_IMAGES: '../dataset/valid'\n",
        "VALID_DIR_LABELS: '../dataset/valid'\n",
        "\n",
        "# Class names.\n",
        "CLASSES: [\n",
        "    '__background__',\n",
        "    'button',\n",
        "    'input',\n",
        "    'checkbox',\n",
        "    'dropdown',\n",
        "    'label',\n",
        "    'icon',\n",
        "    'radio',\n",
        "    'switch'\n",
        "]\n",
        "\n",
        "# Number of classes (object classes + 1 for background class in Faster RCNN).\n",
        "NC: 9\n",
        "\n",
        "# Whether to save the predictions of the validation set while training.\n",
        "SAVE_VALID_PREDICTION_IMAGES: True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Config Setup\n",
        "Run the code block for train setup and then run the code below to start training or copy the generic command and run it in the terminal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_file = 'train.py'\n",
        "eval_file = 'eval.py'\n",
        "export_file = 'export.py'\n",
        "inference_file = 'onnx_inference_image.py'\n",
        "\n",
        "\n",
        "model = 'resnet101'\n",
        "model_name = 'output_resnet101'\n",
        "data = 'custom_data.yaml'\n",
        "inference_dataset = '../dataset/test/'\n",
        "epoch_num = 40\n",
        "batch_size = 4\n",
        "image_size = 1024\n",
        "width = image_size\n",
        "height = image_size\n",
        "inference_score_threshold = 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4iJEC0zjzE5"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_command = f'python {train_file} --model {model} --data {data} --epochs {epoch_num} --batch {batch_size} --imgsz {image_size} --name {model_name} -st'\n",
        "print(f\"Either run the following command in terminal or run the cell below:\\n{train_command}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1BoCmE3j54d",
        "outputId": "42c2693c-cd83-4937-e7d4-b61a64a755ff"
      },
      "outputs": [],
      "source": [
        "os.system(train_command)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Terminal Command to Run Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python train.py --model <model_name> --data custom_data.yaml --epochs <epoch> --batch <batch> --imgsz <size>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Pk7SHEaLJha"
      },
      "source": [
        "## Evaluation\n",
        "Evaluate the model on the distribution of classes in the validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "eval_command = f'python {eval_file} --weights outputs/training/{model_name}/best_model.pth --data {data} --model {model} --verbose'\n",
        "print(f\"Either run the following command in terminal or run the cell below:\\n{eval_command}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.system(eval_command)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Terminal Command to Run Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lk1_AJZU3LiO"
      },
      "outputs": [],
      "source": [
        "!python eval.py --weights outputs/training/<model_name>/best_model.pth --data custom_data.yaml --model <model_name> --verbose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Export model\n",
        "Export model for deployment/inference.\n",
        "Exported models are saved as model.onnx files in a folder structured as weights/model_name/number/model.onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "export_command = f'python {export_file} --model {model} -w outputs/training/{model_name}/best_model.pth --data {data} --file_name {model_name} --width {image_size} --height {image_size}'\n",
        "print(f\"Either run the following command in terminal or run the cell below:\\n{export_command}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.system(export_command)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Terminal Command to Run Export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtuz9gfo3O20",
        "outputId": "f6fc819f-5537-4bd4-ae9d-ae50a9ca0b31"
      },
      "outputs": [],
      "source": [
        "!python export.py --model <model_name> --data custom_data.yaml --out <name> --width <size> --height <size> --file_name <f_name>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Inferences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inference_command = f'python {inference_file} -i {inference_dataset} --data {data} -w weights/{model}/{model_name}/model.onnx -th {inference_score_threshold} -nlb -ncsv'\n",
        "print(f\"Either run the following command in terminal or run the cell below:\\n{inference_command}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.system(inference_command)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Terminal Command to Run Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1BznPkIFWZ4",
        "outputId": "1d1ea816-6a47-494f-97b1-089bacce2fed"
      },
      "outputs": [],
      "source": [
        "!python onnx_inference_image.py -i datasets/<file> --data custom_data.yaml -w weights/<model_name>/<number>/model.onnx -th 0.5 -nlb -ncsv --image <size> --batch <size> --epoch <count>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inference viewer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "old_num = 0\n",
        "infer_path = ''\n",
        "for file in '/outputs/inference/':\n",
        "    new_num = int(file.split('_')[1])\n",
        "    if new_num > old_num:\n",
        "        old_num = new_num\n",
        "        infer_path = file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iFXrfg4dzqqf",
        "outputId": "3bf8a9fe-0933-40a0-f23d-ed00c6a40b73"
      },
      "outputs": [],
      "source": [
        "from cv2 import imshow as cv2_imshow\n",
        "import glob as glob\n",
        "import os\n",
        "import cv2\n",
        "try:\n",
        "  images = glob.glob(infer_path + '/*.jpg')\n",
        "  for i in range(len(images)):\n",
        "    image_name = images[i].split(os.path.sep)[-1].split('.')[0]\n",
        "    image = cv2.imread(images[i])\n",
        "\n",
        "  # if image.shape[0] > 640:\n",
        "  #   cv2_imshow('',image)\n",
        "except:\n",
        "  print('No images found in inference folder')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
